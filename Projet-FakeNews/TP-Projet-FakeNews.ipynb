{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "> **⚠️ EN COURS DE CONSTRUCTION**\n>\n> Ce notebook est en cours de finalisation. Merci de ne pas le consulter pour l'instant.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet - Détecteur de Fake News\n",
    "\n",
    "**Module** : Réseaux de Neurones Approfondissement  \n",
    "**Durée** : 4h (2 sessions)  \n",
    "**Prérequis** : TPs 1-4 (Fondamentaux NLP, Attention, Multi-Head, Transformer)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs du projet\n",
    "\n",
    "Dans ce projet, vous allez :\n",
    "\n",
    "**Partie 1 - From Scratch (2h)**\n",
    "1. Créer un tokenizer simple\n",
    "2. Entraîner votre Transformer des TPs précédents\n",
    "3. Évaluer les performances\n",
    "\n",
    "**Partie 2 - Fine-tuning (2h)**\n",
    "4. Utiliser un modèle pré-entraîné (DistilBERT)\n",
    "5. Comparer les performances\n",
    "6. Créer un pipeline multilingue (FR→EN→Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTIE 1 : Classification From Scratch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installation et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers datasets matplotlib numpy scikit-learn tqdm seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Notre Transformer (des TPs précédents)\n",
    "\n",
    "Nous réutilisons les composants développés dans les TPs 2, 3 et 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Composants du Transformer (TPs 2-4) ===\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = embed_dim // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(embed_dim, embed_dim)\n",
    "        self.W_k = nn.Linear(embed_dim, embed_dim)\n",
    "        self.W_v = nn.Linear(embed_dim, embed_dim)\n",
    "        self.W_o = nn.Linear(embed_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        B, S, _ = x.shape\n",
    "        Q = self.W_q(x).view(B, S, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(x).view(B, S, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(B, S, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        scores = Q @ K.transpose(-2, -1) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        out = (attn @ V).transpose(1, 2).contiguous().view(B, S, self.embed_dim)\n",
    "        return self.W_o(out), attn\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_dim, ff_dim=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        ff_dim = ff_dim or 4 * embed_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[:, :x.size(1)])\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(embed_dim, num_heads)\n",
    "        self.ff = FeedForward(embed_dim, ff_dim, dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out, _ = self.attn(self.norm1(x), mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = x + self.dropout(self.ff(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, num_classes,\n",
    "                 max_len=512, dropout=0.1, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.pos_encoding = PositionalEncoding(embed_dim, max_len, dropout)\n",
    "        self.layers = nn.ModuleList([TransformerBlock(embed_dim, num_heads, dropout=dropout) \n",
    "                                     for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "        self.embed_dim = embed_dim\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x) * math.sqrt(self.embed_dim)\n",
    "        x = self.pos_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        x = self.norm(x)\n",
    "        # Moyenne sur tous les tokens (alternative à [CLS])\n",
    "        x = x.mean(dim=1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "print(\"Transformer chargé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Chargement du Dataset\n",
    "\n",
    "Nous utilisons le dataset LIAR, un dataset de fact-checking en anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Charger le dataset LIAR (fact-checking)\n",
    "print(\"Chargement du dataset...\")\n",
    "dataset = load_dataset(\"liar\", trust_remote_code=True)\n",
    "\n",
    "print(f\"\\nStructure du dataset:\")\n",
    "print(dataset)\n",
    "\n",
    "print(f\"\\nExemple:\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le dataset LIAR a 6 labels, simplifions en 2 (fake vs real)\n",
    "# Labels originaux: pants-fire, false, barely-true, half-true, mostly-true, true\n",
    "# Fake: pants-fire, false, barely-true (0, 1, 2)\n",
    "# Real: half-true, mostly-true, true (3, 4, 5)\n",
    "\n",
    "def simplify_label(example):\n",
    "    example['binary_label'] = 0 if example['label'] < 3 else 1\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(simplify_label)\n",
    "\n",
    "# Vérifier la distribution\n",
    "train_labels = [ex['binary_label'] for ex in dataset['train']]\n",
    "print(f\"Distribution train: Fake={train_labels.count(0)}, Real={train_labels.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Tokenization\n",
    "\n",
    "On crée un tokenizer simple basé sur les mots (comme vu au TP1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCICE 1 : Créer un vocabulaire\n",
    "# ============================================\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, texts, max_vocab_size=10000, min_freq=2):\n",
    "        \"\"\"\n",
    "        Tokenizer simple basé sur les mots.\n",
    "        \"\"\"\n",
    "        self.pad_token = '<PAD>'\n",
    "        self.unk_token = '<UNK>'\n",
    "        \n",
    "        # Compter les mots\n",
    "        word_counts = Counter()\n",
    "        for text in texts:\n",
    "            words = text.lower().split()\n",
    "            word_counts.update(words)\n",
    "        \n",
    "        # TODO: Créer word2idx et idx2word\n",
    "        # 1. Commencer par les tokens spéciaux (PAD=0, UNK=1)\n",
    "        # 2. Ajouter les mots les plus fréquents (>= min_freq)\n",
    "        # 3. Limiter à max_vocab_size\n",
    "        \n",
    "        self.word2idx = None  # À COMPLÉTER\n",
    "        self.idx2word = None  # À COMPLÉTER\n",
    "        self.vocab_size = None  # À COMPLÉTER\n",
    "    \n",
    "    def encode(self, text, max_len=128):\n",
    "        \"\"\"Convertit un texte en indices.\"\"\"\n",
    "        words = text.lower().split()[:max_len]\n",
    "        indices = [self.word2idx.get(w, self.word2idx[self.unk_token]) for w in words]\n",
    "        \n",
    "        # Padding\n",
    "        if len(indices) < max_len:\n",
    "            indices += [self.word2idx[self.pad_token]] * (max_len - len(indices))\n",
    "        \n",
    "        return indices\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        \"\"\"Convertit des indices en texte.\"\"\"\n",
    "        words = [self.idx2word.get(idx, self.unk_token) for idx in indices]\n",
    "        return ' '.join(w for w in words if w != self.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le tokenizer\n",
    "train_texts = [ex['statement'] for ex in dataset['train']]\n",
    "tokenizer = SimpleTokenizer(train_texts, max_vocab_size=8000, min_freq=2)\n",
    "\n",
    "# Test\n",
    "test_text = \"The president said the economy is doing great.\"\n",
    "encoded = tokenizer.encode(test_text, max_len=20)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Encoded: {encoded}\")\n",
    "print(f\"Decoded: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Dataset PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        text = item['statement']\n",
    "        label = item['binary_label']\n",
    "        \n",
    "        input_ids = self.tokenizer.encode(text, self.max_len)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les datasets\n",
    "MAX_LEN = 64\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = FakeNewsDataset(dataset['train'], tokenizer, MAX_LEN)\n",
    "val_dataset = FakeNewsDataset(dataset['validation'], tokenizer, MAX_LEN)\n",
    "test_dataset = FakeNewsDataset(dataset['test'], tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Val: {len(val_dataset)} samples\")\n",
    "print(f\"Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le modèle\n",
    "model_scratch = TransformerClassifier(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embed_dim=128,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    num_classes=2,\n",
    "    max_len=MAX_LEN,\n",
    "    dropout=0.1,\n",
    "    pad_idx=0\n",
    ").to(device)\n",
    "\n",
    "# Compter les paramètres\n",
    "num_params = sum(p.numel() for p in model_scratch.parameters() if p.requires_grad)\n",
    "print(f\"Paramètres: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCICE 2 : Boucle d'entraînement\n",
    "# ============================================\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # TODO: Implémenter la boucle d'entraînement\n",
    "        # 1. Zero grad\n",
    "        # 2. Forward pass\n",
    "        # 3. Calculer la loss\n",
    "        # 4. Backward pass\n",
    "        # 5. Optimizer step\n",
    "        \n",
    "        pass  # À COMPLÉTER\n",
    "        \n",
    "        # Stats (après avoir calculé outputs et loss)\n",
    "        # total_loss += loss.item()\n",
    "        # preds = outputs.argmax(dim=-1)\n",
    "        # correct += (preds == labels).sum().item()\n",
    "        # total += labels.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=-1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EPOCHS = 5\n",
    "LR = 1e-4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_scratch.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Historique\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "print(\"Début de l'entraînement...\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model_scratch, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model_scratch, val_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='Train')\n",
    "axes[1].plot(history['val_acc'], label='Val')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Évaluation sur le Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation finale\n",
    "test_loss, test_acc = evaluate(model_scratch, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy (From Scratch): {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport détaillé\n",
    "model_scratch.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = model_scratch(input_ids)\n",
    "        preds = outputs.argmax(dim=-1).cpu()\n",
    "        \n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labels.tolist())\n",
    "\n",
    "print(\"Classification Report (From Scratch):\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Fake', 'Real']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Fake', 'Real'],\n",
    "            yticklabels=['Fake', 'Real'])\n",
    "plt.xlabel('Prédiction')\n",
    "plt.ylabel('Vérité')\n",
    "plt.title('Matrice de Confusion (From Scratch)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTIE 2 : Fine-tuning avec DistilBERT\n",
    "\n",
    "---\n",
    "\n",
    "Maintenant, comparons avec un modèle pré-entraîné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Charger DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger tokenizer et modèle\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(model_name)\n",
    "model_bert = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2\n",
    ").to(device)\n",
    "\n",
    "num_params_bert = sum(p.numel() for p in model_bert.parameters())\n",
    "print(f\"Modèle chargé: {model_name}\")\n",
    "print(f\"Paramètres: {num_params_bert:,}\")\n",
    "print(f\"\\nComparaison: From Scratch = {num_params:,} | DistilBERT = {num_params_bert:,}\")\n",
    "print(f\"Ratio: DistilBERT est {num_params_bert/num_params:.0f}x plus grand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données pour HuggingFace\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer_bert(\n",
    "        examples['statement'], \n",
    "        padding='max_length', \n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Recharger le dataset pour éviter les conflits\n",
    "dataset_hf = load_dataset(\"liar\", trust_remote_code=True)\n",
    "dataset_hf = dataset_hf.map(simplify_label)\n",
    "\n",
    "# Tokenizer le dataset\n",
    "tokenized_dataset = dataset_hf.map(tokenize_function, batched=True)\n",
    "\n",
    "# Renommer la colonne label\n",
    "tokenized_dataset = tokenized_dataset.rename_column('binary_label', 'labels')\n",
    "\n",
    "# Garder seulement les colonnes nécessaires\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(\n",
    "    [c for c in tokenized_dataset['train'].column_names \n",
    "     if c not in ['input_ids', 'attention_mask', 'labels']]\n",
    ")\n",
    "\n",
    "tokenized_dataset.set_format('torch')\n",
    "print(\"Dataset tokenisé pour DistilBERT !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fine-tuning avec Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'entraînement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Métriques\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model_bert,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner\n",
    "print(\"Entraînement de DistilBERT...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation\n",
    "results = trainer.evaluate(tokenized_dataset['test'])\n",
    "print(f\"\\nRésultats sur le test set:\")\n",
    "print(f\"Accuracy (DistilBERT): {results['eval_accuracy']:.4f}\")\n",
    "print(f\"\\nComparaison:\")\n",
    "print(f\"  From Scratch: {test_acc:.4f}\")\n",
    "print(f\"  DistilBERT:   {results['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Pipeline multilingue (FR → EN → Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Créer les pipelines\n",
    "print(\"Chargement du traducteur...\")\n",
    "translator = pipeline(\"translation_fr_to_en\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "classifier = pipeline(\n",
    "    \"text-classification\", \n",
    "    model=model_bert, \n",
    "    tokenizer=tokenizer_bert, \n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "print(\"Pipelines créés !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCICE 3 : Pipeline FR → Classification\n",
    "# ============================================\n",
    "\n",
    "class FakeNewsDetectorPro:\n",
    "    \"\"\"\n",
    "    Détecteur de Fake News avancé avec support multilingue.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, classifier, translator=None):\n",
    "        self.classifier = classifier\n",
    "        self.translator = translator\n",
    "        self.label_map = {'LABEL_0': 'FAKE', 'LABEL_1': 'REAL'}\n",
    "    \n",
    "    def predict(self, text, source_lang='en'):\n",
    "        \"\"\"\n",
    "        Prédit si un texte est une fake news.\n",
    "        \n",
    "        Args:\n",
    "            text: Texte à analyser\n",
    "            source_lang: Langue du texte ('en' ou 'fr')\n",
    "        \n",
    "        Returns:\n",
    "            dict avec 'label', 'confidence', 'translation'\n",
    "        \"\"\"\n",
    "        # TODO: Implémenter\n",
    "        # 1. Si source_lang == 'fr' et translator existe, traduire\n",
    "        # 2. Classifier le texte (traduit ou original)\n",
    "        # 3. Retourner un dict avec les résultats\n",
    "        \n",
    "        pass  # À COMPLÉTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le détecteur\n",
    "detector = FakeNewsDetectorPro(classifier, translator)\n",
    "\n",
    "# Tests en français\n",
    "tests_fr = [\n",
    "    \"Le gouvernement a annoncé une réforme des retraites.\",\n",
    "    \"Les vaccins contiennent des puces 5G pour nous contrôler.\",\n",
    "    \"L'économie française a progressé de 0.5% ce trimestre.\",\n",
    "    \"Des pyramides ont été découvertes sur Mars par la NASA.\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DÉTECTION DE FAKE NEWS (Français)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for text in tests_fr:\n",
    "    result = detector.predict(text, source_lang='fr')\n",
    "    if result:  # Si l'exercice est complété\n",
    "        emoji = \"❌\" if result['label'] == 'FAKE' else \"✅\"\n",
    "        print(f\"\\n{emoji} {result['label']} ({result['confidence']:.1%})\")\n",
    "        print(f\"   FR: {text}\")\n",
    "        if result.get('translation'):\n",
    "            print(f\"   EN: {result['translation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Analyse comparative\n",
    "\n",
    "Comparons les deux approches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXERCICE 4 : Tableau comparatif\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARAISON DES APPROCHES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n{'Métrique':<25} {'From Scratch':<15} {'DistilBERT':<15}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# TODO: Compléter le tableau avec vos résultats\n",
    "print(f\"{'Paramètres':<25} {num_params:,}\")\n",
    "print(f\"{'Test Accuracy':<25} {test_acc:.4f}\")\n",
    "print(f\"{'Epochs':<25} 5\")\n",
    "\n",
    "# Questions de réflexion :\n",
    "# 1. Pourquoi DistilBERT obtient-il de meilleurs résultats ?\n",
    "# 2. Quels sont les avantages de l'approche From Scratch ?\n",
    "# 3. Dans quel contexte utiliseriez-vous chaque approche ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Analyse des erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les erreurs sur un échantillon\n",
    "test_data = dataset['test']\n",
    "\n",
    "sample_size = 100\n",
    "indices = np.random.choice(len(test_data), sample_size, replace=False)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for idx in tqdm(indices, desc=\"Analyse\"):\n",
    "    item = test_data[int(idx)]\n",
    "    text = item['statement']\n",
    "    true_label = item['binary_label']\n",
    "    \n",
    "    result = classifier(text)[0]\n",
    "    pred_label = 0 if result['label'] == 'LABEL_0' else 1\n",
    "    \n",
    "    if pred_label != true_label:\n",
    "        errors.append({\n",
    "            'text': text,\n",
    "            'true': 'FAKE' if true_label == 0 else 'REAL',\n",
    "            'pred': 'FAKE' if pred_label == 0 else 'REAL',\n",
    "            'confidence': result['score']\n",
    "        })\n",
    "\n",
    "print(f\"\\nErreurs trouvées: {len(errors)}/{sample_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examiner quelques erreurs\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXEMPLES D'ERREURS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, err in enumerate(errors[:5]):\n",
    "    print(f\"\\n[{i+1}] {err['text'][:80]}...\")\n",
    "    print(f\"    Vérité: {err['true']} | Prédiction: {err['pred']} ({err['confidence']:.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Conclusion\n",
    "\n",
    "### Ce que vous avez appris\n",
    "\n",
    "**Partie 1 - From Scratch :**\n",
    "- Créer un tokenizer simple\n",
    "- Réutiliser les composants des TPs précédents\n",
    "- Implémenter une boucle d'entraînement complète\n",
    "\n",
    "**Partie 2 - Fine-tuning :**\n",
    "- Utiliser des modèles pré-entraînés (HuggingFace)\n",
    "- Fine-tuner avec le Trainer\n",
    "- Créer un pipeline multilingue\n",
    "\n",
    "### Comparaison\n",
    "\n",
    "| Aspect | From Scratch | Fine-tuning |\n",
    "|--------|-------------|-------------|\n",
    "| Compréhension | ✅ Totale | ⚠️ Boîte noire |\n",
    "| Performance | ⚠️ Limitée | ✅ État de l'art |\n",
    "| Temps dev | ⚠️ Long | ✅ Rapide |\n",
    "| Données requises | ⚠️ Beaucoup | ✅ Peu |\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Dataset anglais → Biais culturels\n",
    "- Détecte des **patterns**, pas des **faits**\n",
    "- Traduction peut introduire des erreurs\n",
    "\n",
    "### Pour aller plus loin\n",
    "\n",
    "- Modèles multilingues (mBERT, XLM-RoBERTa)\n",
    "- Intégration de sources de fact-checking\n",
    "- Analyse de la source et du contexte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}