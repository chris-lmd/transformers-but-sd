{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# TP 06 - Exploration : Comprendre le Fine-tuning\n\n**Objectif** : Explorer et comprendre les techniques utilis√©es pour le fine-tuning\n\n> **Note** : Ce notebook est con√ßu pour √™tre explor√© **pendant que l'entra√Ænement tourne** dans le notebook principal.\n\n## Sommaire\n1. Explorer le dataset Pok√©mon\n2. Comprendre le filtrage\n3. Tokenisation et ajout de tokens\n4. **D√©mo : Effet du Smart Token Initialization**\n5. Comprendre le freezing des couches\n6. Comprendre les hyperparam√®tres"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. Installation et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Explorer le dataset Pok√©mon\n",
    "\n",
    "On utilise deux datasets :\n",
    "- **pokepedia-fr** : Articles de Pokepedia (wiki Pok√©mon francophone)\n",
    "- **pokemon-names-fr** : Liste des noms de Pok√©mon en fran√ßais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les datasets\n",
    "print(\"Chargement des datasets...\")\n",
    "\n",
    "dataset_pokepedia = load_dataset(\"chris-lmd/pokepedia-fr\")\n",
    "dataset_names = load_dataset(\"chris-lmd/pokemon-names-fr\")\n",
    "\n",
    "POKEMON_NAMES = [item[\"name\"] for item in dataset_names[\"train\"]]\n",
    "\n",
    "print(f\"\\nüìö Pokepedia : {len(dataset_pokepedia['train']):,} articles\")\n",
    "print(f\"üìã Noms de Pok√©mon : {len(POKEMON_NAMES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples de noms\n",
    "print(\"Premiers noms :\")\n",
    "print(POKEMON_NAMES[:20])\n",
    "\n",
    "print(\"\\nDerniers noms :\")\n",
    "print(POKEMON_NAMES[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu d'un article\n",
    "article = dataset_pokepedia['train'][0]\n",
    "\n",
    "print(f\"Titre : {article['title']}\")\n",
    "print(f\"\\nContenu (extrait) :\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "print(article['content'][:1000])\n",
    "print(\"‚îÄ\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorer diff√©rents types d'articles\n",
    "print(\"‚ïê\" * 50)\n",
    "print(\"Exemples de titres d'articles :\")\n",
    "print(\"‚ïê\" * 50)\n",
    "\n",
    "for i in [0, 100, 500, 1000, 2000, 5000, 10000]:\n",
    "    if i < len(dataset_pokepedia['train']):\n",
    "        title = dataset_pokepedia['train'][i]['title']\n",
    "        print(f\"  [{i:5d}] {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Tous les articles ne sont pas des descriptions de Pok√©mon."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Comprendre le filtrage\n",
    "\n",
    "Le dataset Pokepedia contient **diff√©rents types d'articles** :\n",
    "- Descriptions de Pok√©mon (ce qu'on veut)\n",
    "- √âpisodes d'anime\n",
    "- Lieux\n",
    "- Personnages\n",
    "- Objets\n",
    "- ...\n",
    "\n",
    "Si on entra√Æne sur tout, le mod√®le apprend un m√©lange incoh√©rent !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un set des noms pour recherche rapide\n",
    "pokemon_names_set = set(name.lower() for name in POKEMON_NAMES)\n",
    "\n",
    "def is_pokemon_article(example):\n",
    "    \"\"\"V√©rifie si le titre de l'article est un nom de Pok√©mon.\"\"\"\n",
    "    title = example.get('title', '').lower()\n",
    "    return title in pokemon_names_set\n",
    "\n",
    "# Filtrer\n",
    "pokemon_articles = dataset_pokepedia['train'].filter(is_pokemon_article)\n",
    "other_articles = dataset_pokepedia['train'].filter(lambda x: not is_pokemon_article(x))\n",
    "\n",
    "print(\"‚ïê\" * 50)\n",
    "print(\"R√©sultat du filtrage\")\n",
    "print(\"‚ïê\" * 50)\n",
    "print(f\"Total articles        : {len(dataset_pokepedia['train']):,}\")\n",
    "print(f\"Articles Pok√©mon      : {len(pokemon_articles):,} ‚úÖ\")\n",
    "print(f\"Autres articles       : {len(other_articles):,} ‚ùå\")\n",
    "print(f\"\\nRatio Pok√©mon : {100*len(pokemon_articles)/len(dataset_pokepedia['train']):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples d'articles Pok√©mon (gard√©s)\n",
    "print(\"\\n‚úÖ Articles POK√âMON (gard√©s pour l'entra√Ænement) :\")\n",
    "for i in range(min(10, len(pokemon_articles))):\n",
    "    print(f\"   - {pokemon_articles[i]['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples d'articles NON-Pok√©mon (exclus)\n",
    "print(\"\\n‚ùå Articles NON-POK√âMON (exclus) :\")\n",
    "for i in range(min(15, len(other_articles))):\n",
    "    print(f\"   - {other_articles[i]['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer le contenu d'un article Pok√©mon vs un autre\n",
    "print(\"‚ïê\" * 60)\n",
    "print(\"COMPARAISON : Article Pok√©mon vs Autre\")\n",
    "print(\"‚ïê\" * 60)\n",
    "\n",
    "print(\"\\nüìó ARTICLE POK√âMON :\")\n",
    "print(f\"Titre : {pokemon_articles[0]['title']}\")\n",
    "print(f\"Contenu : {pokemon_articles[0]['content'][:400]}...\")\n",
    "\n",
    "print(\"\\n\" + \"‚îÄ\" * 60)\n",
    "\n",
    "print(\"\\nüìï AUTRE ARTICLE :\")\n",
    "print(f\"Titre : {other_articles[0]['title']}\")\n",
    "print(f\"Contenu : {other_articles[0]['content'][:400]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pourquoi filtrer ?\n",
    "\n",
    "| Sans filtrage | Avec filtrage |\n",
    "|---------------|---------------|\n",
    "| ~15,000 articles m√©lang√©s | ~1,200 vrais Pok√©mon |\n",
    "| Anime, lieux, persos... | Descriptions uniquement |\n",
    "| R√©sultat incoh√©rent | Style Pok√©dex coh√©rent |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Tokenisation et vocabulaire\n",
    "\n",
    "GPT-2 utilise **BPE** (Byte Pair Encoding) pour d√©couper le texte en tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le tokenizer\n",
    "print(\"Chargement du tokenizer GPT-2 fran√ßais...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"asi/gpt-fr-cased-base\")\n",
    "print(f\"Vocabulaire : {len(tokenizer):,} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment le tokenizer d√©coupe les noms de Pok√©mon ?\n",
    "test_names = [\"Pikachu\", \"Dracaufeu\", \"Bulbizarre\", \"Salam√®che\", \"Mewtwo\", \"Rondoudou\"]\n",
    "\n",
    "print(\"‚ïê\" * 60)\n",
    "print(\"Comment GPT-2 tokenise les noms de Pok√©mon ?\")\n",
    "print(\"‚ïê\" * 60)\n",
    "\n",
    "for name in test_names:\n",
    "    tokens = tokenizer.tokenize(name)\n",
    "    n_tokens = len(tokens)\n",
    "    status = \"‚úÖ 1 token\" if n_tokens == 1 else f\"‚ùå {n_tokens} tokens\"\n",
    "    print(f\"  '{name}' ‚Üí {tokens} ({status})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques sur tous les noms\n",
    "single_token = 0\n",
    "multi_token = 0\n",
    "\n",
    "for name in POKEMON_NAMES:\n",
    "    tokens = tokenizer.encode(name, add_special_tokens=False)\n",
    "    if len(tokens) == 1:\n",
    "        single_token += 1\n",
    "    else:\n",
    "        multi_token += 1\n",
    "\n",
    "print(f\"\\nüìä Statistiques sur {len(POKEMON_NAMES)} noms :\")\n",
    "print(f\"   D√©j√† dans le vocabulaire (1 token) : {single_token}\")\n",
    "print(f\"   D√©coup√©s en plusieurs tokens       : {multi_token}\")\n",
    "print(f\"\\n   ‚Üí {multi_token} tokens √† ajouter !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. D√©mo : Smart Token Initialization\n",
    "\n",
    "**Id√©e** : Quand on ajoute \"Pikachu\" au vocabulaire, on l'initialise avec l'embedding de \"animal\" (pas al√©atoire).\n",
    "\n",
    "**Pourquoi ?** Le mod√®le sait d√©j√† que \"Pikachu\" est une sorte d'animal/cr√©ature, m√™me sans entra√Ænement.\n",
    "\n",
    "### D√©monstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le mod√®le pour la d√©mo\n",
    "print(\"Chargement du mod√®le GPT-2 pour la d√©mo...\")\n",
    "model_demo = AutoModelForCausalLM.from_pretrained(\"asi/gpt-fr-cased-base\")\n",
    "tokenizer_demo = AutoTokenizer.from_pretrained(\"asi/gpt-fr-cased-base\")\n",
    "tokenizer_demo.pad_token = tokenizer_demo.eos_token\n",
    "\n",
    "model_demo = model_demo.to(device)\n",
    "print(\"‚úÖ Mod√®le charg√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demo(prompt, model, tokenizer, max_length=50):\n",
    "    \"\"\"G√©n√®re du texte (pour la d√©mo).\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            top_k=50,\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# √âTAPE 1 : G√©n√©ration AVANT ajout du token \"Pikachu\"\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"‚ïê\" * 60)\n",
    "print(\"AVANT ajout du token 'Pikachu'\")\n",
    "print(\"‚ïê\" * 60)\n",
    "\n",
    "print(f\"\\nTokenisation de 'Pikachu' : {tokenizer_demo.tokenize('Pikachu')}\")\n",
    "print(\"‚Üí Le mod√®le voit des syllabes sans sens particulier\")\n",
    "\n",
    "prompt = \"Pikachu est un\"\n",
    "print(f\"\\nPrompt : '{prompt}'\")\n",
    "print(\"G√©n√©ration :\")\n",
    "for i in range(3):\n",
    "    result = generate_demo(prompt, model_demo, tokenizer_demo)\n",
    "    print(f\"  {i+1}. {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# √âTAPE 2 : Ajouter \"Pikachu\" initialis√© avec \"animal\"\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"‚ïê\" * 60)\n",
    "print(\"Ajout du token 'Pikachu' (initialis√© avec 'animal')\")\n",
    "print(\"‚ïê\" * 60)\n",
    "\n",
    "# Trouver l'ID de \"animal\"\n",
    "animal_tokens = tokenizer_demo.encode(\"animal\", add_special_tokens=False)\n",
    "print(f\"\\n'animal' ‚Üí tokens: {animal_tokens}\")\n",
    "animal_id = animal_tokens[0]\n",
    "\n",
    "# Sauvegarder l'embedding de \"animal\"\n",
    "with torch.no_grad():\n",
    "    animal_embedding = model_demo.transformer.wte.weight[animal_id].clone()\n",
    "\n",
    "# Ajouter \"Pikachu\" au vocabulaire\n",
    "old_vocab_size = len(tokenizer_demo)\n",
    "tokenizer_demo.add_tokens([\"Pikachu\"])\n",
    "model_demo.resize_token_embeddings(len(tokenizer_demo), mean_resizing=False)\n",
    "\n",
    "# Initialiser avec l'embedding de \"animal\"\n",
    "with torch.no_grad():\n",
    "    pikachu_id = old_vocab_size  # Le nouveau token\n",
    "    model_demo.transformer.wte.weight[pikachu_id] = animal_embedding.clone()\n",
    "\n",
    "print(f\"\\n‚úÖ Token 'Pikachu' ajout√© (id={pikachu_id})\")\n",
    "print(f\"   Initialis√© avec l'embedding de 'animal' (id={animal_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# √âTAPE 3 : G√©n√©ration APR√àS ajout du token\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "print(\"‚ïê\" * 60)\n",
    "print(\"APR√àS ajout du token 'Pikachu' (= 'animal')\")\n",
    "print(\"‚ïê\" * 60)\n",
    "\n",
    "print(f\"\\nTokenisation de 'Pikachu' : {tokenizer_demo.tokenize('Pikachu')}\")\n",
    "print(\"‚Üí Maintenant un seul token, √©quivalent √† 'animal' !\")\n",
    "\n",
    "prompt = \"Pikachu est un\"\n",
    "print(f\"\\nPrompt : '{prompt}'\")\n",
    "print(\"G√©n√©ration :\")\n",
    "for i in range(3):\n",
    "    result = generate_demo(prompt, model_demo, tokenizer_demo)\n",
    "    print(f\"  {i+1}. {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avec \"animal est un\"\n",
    "print(\"\\n\" + \"‚ïê\" * 60)\n",
    "print(\"Comparaison : 'animal est un'\")\n",
    "print(\"‚ïê\" * 60)\n",
    "\n",
    "prompt = \"animal est un\"\n",
    "print(f\"\\nPrompt : '{prompt}'\")\n",
    "print(\"G√©n√©ration :\")\n",
    "for i in range(3):\n",
    "    result = generate_demo(prompt, model_demo, tokenizer_demo)\n",
    "    print(f\"  {i+1}. {result}\")\n",
    "\n",
    "print(\"\\n‚Üí Les r√©sultats devraient √™tre similaires !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion de la d√©mo\n",
    "\n",
    "| Avant ajout | Apr√®s ajout (initialis√© avec \"animal\") |\n",
    "|-------------|----------------------------------------|\n",
    "| \"Pikachu\" ‚Üí syllabes al√©atoires | \"Pikachu\" ‚Üí √©quivalent √† \"animal\" |\n",
    "| G√©n√©ration incoh√©rente | G√©n√©ration orient√©e \"√™tre vivant\" |\n",
    "\n",
    "**Le fine-tuning va ensuite** affiner cette repr√©sentation pour que \"Pikachu\" = \"Pok√©mon √©lectrique jaune\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Comprendre le freezing des couches\n",
    "\n",
    "GPT-2 est compos√© de plusieurs couches de Transformer empil√©es.\n",
    "\n",
    "**Couches basses** : Capturent la grammaire, la syntaxe (d√©j√† bien apprises)\n",
    "\n",
    "**Couches hautes** : Capturent la s√©mantique, le style (√† adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser l'architecture\n",
    "print(\"‚ïê\" * 50)\n",
    "print(\"Architecture GPT-2\")\n",
    "print(\"‚ïê\" * 50)\n",
    "print()\n",
    "print(\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"‚îÇ   Token Embeddings (wte)    ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(\"‚îÇ Position Embeddings (wpe)   ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(\"‚îÇ                             ‚îÇ\")\n",
    "print(\"‚îÇ   Transformer Block 0       ‚îÇ\")\n",
    "print(\"‚îÇ   Transformer Block 1       ‚îÇ ‚Üê COUCHES BASSES\")\n",
    "print(\"‚îÇ          ...                ‚îÇ   (fig√©es)\")\n",
    "print(\"‚îÇ   Transformer Block N/2     ‚îÇ\")\n",
    "print(\"‚îÇ                             ‚îÇ\")\n",
    "print(\"‚îú ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ ‚îÄ‚î§\")\n",
    "print(\"‚îÇ                             ‚îÇ\")\n",
    "print(\"‚îÇ   Transformer Block N/2+1   ‚îÇ\")\n",
    "print(\"‚îÇ          ...                ‚îÇ ‚Üê COUCHES HAUTES\")\n",
    "print(\"‚îÇ   Transformer Block N-1     ‚îÇ   (entra√Æn√©es)\")\n",
    "print(\"‚îÇ                             ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(\"‚îÇ      Layer Norm (ln_f)      ‚îÇ\")\n",
    "print(\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(\"‚îÇ        LM Head              ‚îÇ\")\n",
    "print(\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les param√®tres\n",
    "model_count = AutoModelForCausalLM.from_pretrained(\"asi/gpt-fr-cased-base\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model_count.parameters())\n",
    "print(f\"Param√®tres totaux : {total_params:,}\")\n",
    "\n",
    "# Simuler le freezing de 50% des couches\n",
    "n_layers = model_count.config.n_layer\n",
    "n_to_freeze = n_layers // 2\n",
    "\n",
    "# Figer\n",
    "for param in model_count.transformer.wte.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_count.transformer.wpe.parameters():\n",
    "    param.requires_grad = False\n",
    "for i in range(n_to_freeze):\n",
    "    for param in model_count.transformer.h[i].parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "trainable = sum(p.numel() for p in model_count.parameters() if p.requires_grad)\n",
    "frozen = total_params - trainable\n",
    "\n",
    "print(f\"\\nAvec freezing de {n_to_freeze}/{n_layers} couches :\")\n",
    "print(f\"  Param√®tres fig√©s       : {frozen:,} ({100*frozen/total_params:.0f}%)\")\n",
    "print(f\"  Param√®tres entra√Ænables: {trainable:,} ({100*trainable/total_params:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avantages du freezing\n",
    "\n",
    "| Aspect | Sans freezing | Avec freezing 50% |\n",
    "|--------|---------------|-------------------|\n",
    "| Param√®tres √† entra√Æner | 100% | ~45% |\n",
    "| Vitesse | Lent | Plus rapide |\n",
    "| Risque d'overfitting | √âlev√© | R√©duit |\n",
    "| Connaissances linguistiques | Peuvent √™tre \"oubli√©es\" | Pr√©serv√©es |"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 6. Comprendre les hyperparam√®tres\n\nLes hyperparam√®tres contr√¥lent **comment** le mod√®le apprend (entra√Ænement) et **comment** il g√©n√®re du texte (inf√©rence).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 6.1 Param√®tres d'entra√Ænement\n\nCes param√®tres sont d√©finis dans `TrainingArguments` du notebook principal.\n\n#### Batch size et Gradient Accumulation\n\n```python\nper_device_train_batch_size = 2    # Exemples trait√©s en parall√®le sur le GPU\ngradient_accumulation_steps = 8    # Accumule les gradients avant mise √† jour\n```\n\n**Effective batch size** = `batch_size √ó gradient_accumulation` = 2 √ó 8 = **16**\n\nPourquoi ne pas utiliser batch_size=16 directement ?\n- La **m√©moire GPU est limit√©e** (surtout sur Colab gratuit)\n- Avec accumulation, on simule un grand batch sans surcharger la m√©moire",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualisation : Gradient Accumulation\nprint(\"‚ïê\" * 60)\nprint(\"Gradient Accumulation : Comment √ßa marche ?\")\nprint(\"‚ïê\" * 60)\n\nbatch_size = 2\ngrad_accum = 8\n\nprint(f\"\"\"\nSans accumulation (batch_size=16) :\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  16 exemples  ‚îÇ ‚Üí calcul gradients ‚Üí mise √† jour poids   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n  ‚ö†Ô∏è  Peut d√©passer la m√©moire GPU !\n\nAvec accumulation (batch_size=2, accumulation=8) :\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ 2 ex.  ‚îÇ ‚îÇ 2 ex.  ‚îÇ ‚îÇ 2 ex.  ‚îÇ ‚îÇ 2 ex.  ‚îÇ  ...√ó8\n‚îÇ grad 1 ‚îÇ ‚îÇ grad 2 ‚îÇ ‚îÇ grad 3 ‚îÇ ‚îÇ grad 4 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n     ‚Üì          ‚Üì          ‚Üì          ‚Üì\n     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                    ‚Üì\n           Somme des gradients\n                    ‚Üì\n            Mise √† jour poids\n  ‚úÖ  M√™me effet, moins de m√©moire !\n\"\"\")\n\nprint(f\"Effective batch size : {batch_size} √ó {grad_accum} = {batch_size * grad_accum}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Learning Rate (taux d'apprentissage)\n\n```python\nlearning_rate = 5e-5  # = 0.00005\n```\n\nLe learning rate contr√¥le **l'amplitude des mises √† jour** des poids.\n\n| Learning Rate | Effet |\n|---------------|-------|\n| Trop √©lev√© (1e-3) | Apprentissage instable, perte des connaissances pr√©-entra√Æn√©es |\n| Optimal (5e-5) | Apprentissage progressif, pr√©serve les acquis |\n| Trop faible (1e-6) | Apprentissage tr√®s lent, sous-exploitation du dataset |\n\n**Pour le fine-tuning**, on utilise un LR **beaucoup plus petit** que pour l'entra√Ænement from scratch, car on veut ajuster l√©g√®rement un mod√®le d√©j√† performant.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### Epochs (nombre de passes)\n\n```python\nnum_train_epochs = 10\n```\n\nUne **epoch** = une passe compl√®te sur tout le dataset.\n\nAvec ~1200 articles et un effective batch de 16 :\n- **Steps par epoch** = 1200 / 16 ‚âà 75 steps\n- **Total** = 10 epochs √ó 75 = ~750 steps\n\n| Epochs | Risque |\n|--------|--------|\n| Trop peu (1-2) | Sous-apprentissage, le mod√®le n'a pas assez vu les donn√©es |\n| Optimal (5-15) | Bon compromis apprentissage/g√©n√©ralisation |\n| Trop (50+) | **Overfitting** : le mod√®le r√©cite par c≈ìur au lieu de g√©n√©raliser |\n\nOn surveille la **loss** : si elle remonte apr√®s avoir baiss√© ‚Üí overfitting !",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### Warmup (d√©marrage progressif)\n\n```python\nwarmup_steps = 100\n```\n\nLe warmup augmente **progressivement** le learning rate au d√©but de l'entra√Ænement.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualisation du warmup\nprint(\"‚ïê\" * 60)\nprint(\"Learning Rate Schedule avec Warmup\")\nprint(\"‚ïê\" * 60)\n\nprint(\"\"\"\nLearning Rate\n    ‚Üë\n5e-5‚îÇ           ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n    ‚îÇ         ‚ï±                          ‚ï≤\n    ‚îÇ       ‚ï±                              ‚ï≤\n    ‚îÇ     ‚ï±                                  ‚ï≤\n    ‚îÇ   ‚ï±                                      ‚ï≤\n  0 ‚îÇ‚îÄ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï≤‚îÄ‚îÄ‚îÄ‚Üí Steps\n    0   100                                    750\n        ‚Üë\n      Warmup\n      (mont√©e progressive)\n\nPourquoi le warmup ?\n‚Ä¢ Au d√©but, les gradients peuvent √™tre \"bruit√©s\" (le mod√®le d√©couvre les donn√©es)\n‚Ä¢ Un LR √©lev√© d√®s le d√©part peut causer des mises √† jour trop agressives\n‚Ä¢ Le warmup permet une adaptation en douceur\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### MAX_LENGTH (longueur des s√©quences)\n\n```python\nmax_length = 256  # tokens\n```\n\nChaque article est **tronqu√© ou padd√©** √† cette longueur.\n\n| MAX_LENGTH | Effet |\n|------------|-------|\n| Court (128) | Rapide, mais perd la fin des articles longs |\n| Moyen (256) | Bon compromis pour notre dataset |\n| Long (512+) | Plus de contexte, mais plus de m√©moire et plus lent |\n\n**Note** : GPT-2 a une limite de **1024 tokens**. Au-del√†, il faut des techniques sp√©ciales (sliding window, etc.).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 6.2 Param√®tres de g√©n√©ration\n\nCes param√®tres contr√¥lent **comment le mod√®le choisit le prochain token** lors de la g√©n√©ration.\n\n#### Temperature (cr√©ativit√©)\n\n```python\ntemperature = 0.7  # Entre 0 et 2+\n```\n\nLa temp√©rature **modifie la distribution de probabilit√©s** avant le sampling.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# D√©monstration de l'effet de la temp√©rature\nimport torch.nn.functional as F\n\nprint(\"‚ïê\" * 60)\nprint(\"Effet de la temp√©rature sur les probabilit√©s\")\nprint(\"‚ïê\" * 60)\n\n# Logits simul√©s (avant softmax)\nlogits = torch.tensor([2.0, 1.5, 0.5, 0.3, 0.1])\ntokens = [\"√âlectrik\", \"Souris\", \"Jaune\", \"Combat\", \"Roche\"]\n\nprint(\"\\nLogits bruts (scores du mod√®le) :\")\nfor t, l in zip(tokens, logits):\n    print(f\"  {t:10} : {l:.1f}\")\n\nprint(\"\\n\" + \"‚îÄ\" * 60)\n\nfor temp in [0.3, 0.7, 1.0, 1.5]:\n    probs = F.softmax(logits / temp, dim=0)\n    print(f\"\\nTemperature = {temp}\")\n    for t, p in zip(tokens, probs):\n        bar = \"‚ñà\" * int(p * 30)\n        print(f\"  {t:10} : {p:.1%} {bar}\")\n\nprint(\"\\n\" + \"‚ïê\" * 60)\nprint(\"\"\"\nInterpr√©tation :\n‚Ä¢ T=0.3 (froid) : Le token dominant (\"√âlectrik\") est quasi-certain\n                  ‚Üí G√©n√©ration pr√©visible, r√©p√©titive\n‚Ä¢ T=0.7 (ti√®de) : Bon √©quilibre cr√©ativit√©/coh√©rence  \n‚Ä¢ T=1.0 (neutre): Distribution originale du mod√®le\n‚Ä¢ T=1.5 (chaud) : Distribution aplatie, plus de surprises\n                  ‚Üí G√©n√©ration cr√©ative mais parfois incoh√©rente\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Top-k et Top-p (filtrage du vocabulaire)\n\nCes param√®tres **limitent les tokens consid√©r√©s** pour le sampling.\n\n```python\ntop_k = 50    # Garde les 50 tokens les plus probables\ntop_p = 0.9   # Garde les tokens jusqu'√† 90% de proba cumul√©e\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# D√©monstration Top-k et Top-p\nprint(\"‚ïê\" * 60)\nprint(\"Top-k vs Top-p : Filtrage des tokens\")\nprint(\"‚ïê\" * 60)\n\n# Distribution simul√©e (tri√©e par probabilit√© d√©croissante)\nprobs = [0.35, 0.25, 0.15, 0.10, 0.05, 0.04, 0.03, 0.02, 0.01]\ntokens = [\"√âlectrik\", \"Souris\", \"Jaune\", \"petit\", \"Pokemon\", \"type\", \"est\", \"a\", \"le\"]\n\nprint(\"\\nDistribution originale :\")\ncumsum = 0\nfor i, (t, p) in enumerate(zip(tokens, probs)):\n    cumsum += p\n    bar = \"‚ñà\" * int(p * 40)\n    print(f\"  {i+1}. {t:10} : {p:.0%} {bar}  (cumul: {cumsum:.0%})\")\n\nprint(\"\\n\" + \"‚îÄ\" * 60)\n\nprint(\"\"\"\nTop-k = 3 : Garde seulement les 3 premiers tokens\n  ‚úÖ √âlectrik (35%)\n  ‚úÖ Souris   (25%)  \n  ‚úÖ Jaune    (15%)\n  ‚ùå petit, Pokemon, type... (ignor√©s)\n  \n  ‚Üí Renormalise sur ces 3 tokens (35+25+15 = 75% ‚Üí 100%)\n\"\"\")\n\nprint(\"‚îÄ\" * 60)\n\nprint(\"\"\"\nTop-p = 0.9 : Garde les tokens jusqu'√† 90% de proba cumul√©e\n  ‚úÖ √âlectrik (35%)  cumul: 35%\n  ‚úÖ Souris   (25%)  cumul: 60%\n  ‚úÖ Jaune    (15%)  cumul: 75%\n  ‚úÖ petit    (10%)  cumul: 85%\n  ‚úÖ Pokemon  (5%)   cumul: 90% ‚Üê STOP\n  ‚ùå type, est, a, le... (ignor√©s)\n  \n  ‚Üí Plus flexible que top-k : s'adapte √† la distribution\n\"\"\")\n\nprint(\"‚ïê\" * 60)\nprint(\"\"\"\nEn pratique, on combine souvent les deux :\n  top_k=50, top_p=0.9 ‚Üí garde au max 50 tokens ET 90% de proba\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Repetition Penalty (√©viter les boucles)\n\n```python\nrepetition_penalty = 1.2  # > 1 p√©nalise les r√©p√©titions\n```\n\nDivise la probabilit√© des tokens **d√©j√† g√©n√©r√©s** pour √©viter les boucles.\n\n| Valeur | Effet |\n|--------|-------|\n| 1.0 | Pas de p√©nalit√© (r√©p√©titions possibles) |\n| 1.2 | L√©g√®re p√©nalit√© (recommand√©) |\n| 2.0+ | Forte p√©nalit√© (peut devenir incoh√©rent) |\n\n**Exemple sans p√©nalit√©** :\n> \"Pikachu est un Pok√©mon. Pikachu est un Pok√©mon. Pikachu est un Pok√©mon...\"\n\n**Avec p√©nalit√© 1.2** :\n> \"Pikachu est un Pok√©mon de type √âlectrik. Il poss√®de des pouvoirs...\"",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### R√©capitulatif des param√®tres de g√©n√©ration\n\n| Param√®tre | Valeur TP | R√¥le | Effet si ‚Üë |\n|-----------|-----------|------|------------|\n| `temperature` | 0.7 | Contr√¥le la \"cr√©ativit√©\" | Plus al√©atoire, moins coh√©rent |\n| `top_k` | 50 | Nombre max de tokens candidats | Plus de diversit√© |\n| `top_p` | 0.9 | Seuil de probabilit√© cumul√©e | Plus de tokens rares possibles |\n| `repetition_penalty` | 1.2 | P√©nalise les r√©p√©titions | Moins de boucles, mais peut diverger |\n| `max_length` | 150 | Longueur max de g√©n√©ration | Texte plus long |\n\n**Conseil** : Pour tester votre mod√®le fine-tun√©, commencez avec `temperature=0.5` (coh√©rent) puis augmentez pour plus de cr√©ativit√©.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## R√©capitulatif\n\n### Techniques vues dans ce notebook\n\n1. **Filtrage du dataset** : Ne garder que les vrais articles Pok√©mon (~1200 sur ~15000)\n\n2. **Smart Token Initialization** : Ajouter les noms au vocabulaire, initialis√©s avec \"animal\"\n\n3. **Partial Freezing** : Figer les couches basses pour pr√©server les connaissances linguistiques\n\n4. **Hyperparam√®tres d'entra√Ænement** : batch size, learning rate, epochs, warmup\n\n5. **Hyperparam√®tres de g√©n√©ration** : temperature, top-k, top-p, repetition penalty\n\n### Retournez voir les r√©sultats !\n\nL'entra√Ænement devrait √™tre termin√© dans le notebook principal. Allez voir :\n- La courbe de loss\n- Les g√©n√©rations de texte\n\n**Exp√©rimentez** avec diff√©rentes temp√©ratures pour voir l'effet sur la cr√©ativit√© !"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
