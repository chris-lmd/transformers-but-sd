# Notebooks - Sessions 2 à 6

| Session | Notebook | Colab |
|---------|----------|-------|
| 2 | TP-02-PE_et_Bases_Attention | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chris-lmd/transformers-but-sd/blob/main/tmp/TP-02-PE_et_Bases_Attention.ipynb) |
| 3 | TP-03-Attention | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chris-lmd/transformers-but-sd/blob/main/tmp/TP-03-Attention.ipynb) |
| 4 | TP-04-MultiHead-Transformer | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chris-lmd/transformers-but-sd/blob/main/tmp/TP-04-MultiHead-Transformer.ipynb) |
| 5 | TP-05-MiniGPT-Noms | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chris-lmd/transformers-but-sd/blob/main/tmp/TP-05-MiniGPT-Noms.ipynb) |
| 6 | TP-06-MiniGPT-FineTuning | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chris-lmd/transformers-but-sd/blob/main/tmp/TP-06-MiniGPT-FineTuning.ipynb) |

## Notes complémentaires

| Sujet | Notebook | Colab |
|-------|----------|-------|
| Positional Encoding | Note-Positional-Encoding | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chris-lmd/transformers-but-sd/blob/main/tmp/Note-Positional-Encoding.ipynb) |
| Mécanisme d'Attention | Note-Attention | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chris-lmd/transformers-but-sd/blob/main/tmp/Note-Attention.ipynb) |
